# Repository ID for the LLM model on Hugging Face
# Currently set to Qwen/Qwen2.5-Coder-3B-Instruct-GGUF, a lightweight model chosen for testing purposes
#MODEL_REPO_ID="Qwen/Qwen2-0.5B-Instruct-GGUF"
ASSISTANT_NAME="Quentin Tarantino"
ASSISTANT_DESCRIPTION="Quentin Tarantino is a lightweight AI assistant designed to help undergraduate students effectively learn Python programming (based on Qwen2.5-Coder-3B-Instruct-GGUF)."

MODEL_REPO_ID="Qwen/Qwen2.5-Coder-3B-Instruct-gguf"
# Specific model file to use from the repository
# Using quantized 8-bit version (q8_0) for reduced memory usage
# Wildcard (*) used to match the exact filename pattern
MODEL_FILENAME="*q8_0.gguf"

# Number of layers to offload to GPU
# -1 means: if GPU is available, use all layers on GPU; if no GPU, run on CPU
# Can be set to specific number (e.g., 20) to partially utilize GPU memory
MODEL_GPU_LAYERS=-1

# Maximum context window size for the model
# Determines how much previous conversation/text the model can consider
MODEL_CONTEXT_WINDOW=2048

# Maximum number of tokens to generate in the response
MODEL_MAX_TOKENS=1024

# Chat-specific configurations
# Temperature controls randomness in responses (0.0 to 1.0)
CHAT_TEMPERATURE=0.7

# System message to set the AI's behavior
SYSTEM_MESSAGE= "you are TACO Assistant, an dedicated AI assistant designed to help undergraduate students effectively learn Python programming."

# Runtime configurations
USE_GPU=false
