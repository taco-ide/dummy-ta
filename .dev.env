# Repository ID for the LLM model on Hugging Face
# Currently set to Qwen2-0.5B-Instruct, a lightweight model chosen for testing purposes
MODEL_REPO_ID="Qwen/Qwen2-0.5B-Instruct-GGUF"

# Specific model file to use from the repository
# Using quantized 8-bit version (q8_0) for reduced memory usage
# Wildcard (*) used to match the exact filename pattern
MODEL_FILENAME="*q8_0.gguf"

# Number of layers to offload to GPU
# -1 means: if GPU is available, use all layers on GPU; if no GPU, run on CPU
# Can be set to specific number (e.g., 20) to partially utilize GPU memory
MODEL_GPU_LAYERS=-1

# Maximum context window size for the model
# Determines how much previous conversation/text the model can consider
MODEL_CONTEXT_WINDOW=2048